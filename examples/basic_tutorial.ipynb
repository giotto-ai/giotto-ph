{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: how to use giotto-ph\n",
    "\n",
    "This tutorial shows the basic functionalities and API of `giotto-ph`.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "`giotto-ph` is a reworked and **parallelised** version of the Vietoris-Rips algorithm. In short, this algorithms computes the homology groups of the Vietoris-Rips filtration. Such filtration is obtained by progressively enlarging a *scale* parameter $\\epsilon$ to build a sequence of simplicial complexes. The simplicial complexes are built based on the intersection of $\\epsilon$-radius bubbbles. Given that the simplicial complexes contain more and more elements as the bubbles inflate, there are canonical injective maps between the complex at $\\epsilon_1$ and the complex at $\\epsilon_2$, with $\\epsilon_1 \\leq \\epsilon_2$ (hence the ffiltration is well defined).\n",
    "\n",
    "In this picture we see the sequence of complexes forming while $\\epsilon$ increases over time. The bubbles are the disks of radius $\\epsilon$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image  # to display images\n",
    "Image(\"images/ph.gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A word on parallelism\n",
    "\n",
    "The parallelism of `giotto-ph` builds on different sources already present in literature: for example, you can have a look [here](https://arxiv.org/abs/2003.07989) and [here](https://www.mrzv.org/publications/lockfree-persistence/spaa/).\n",
    "\n",
    "The basic idea is to parallelise the boundary matrix $\\bf D$ reduction step. Indeed, in order to compute homology, one needs to know the *rank* and the *kernel* of the boundary martrix $\\bf D$ ([here](https://en.wikipedia.org/wiki/Simplicial_homology) for more details). In order to easily read the kernel and the rank from $\\bf D$ (and be able to quotient them to get the homology), the most effective approach is to reduce $\\bf D$ in *echelon form*: the kernel is then the number of columns of all zeros and the rank corresponds to the non-empty rows. In order to reduce the orginal $\\bf D$ to echelon form, we can add columns to one another (from left to right) till convergence: this step does not require a precise order in the operations: it requires only to do the correct operations! Hence, the possibility to parallelise it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install missing dependencies\n",
    "import sys\n",
    "!{sys.executable} -m pip install giotto-tda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here comes our protagonist!\n",
    "from gph import ripser_parallel\n",
    "\n",
    "# Import utils\n",
    "import numpy as np\n",
    "from gtda.homology._utils import _postprocess_diagrams\n",
    "\n",
    "# To generate dataset\n",
    "from sklearn import datasets\n",
    "\n",
    "# Plotting\n",
    "from plotly import graph_objects as go\n",
    "from gtda.plotting import plot_diagram, plot_point_cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the point cloud\n",
    "data = datasets.make_circles(n_samples=100)[0] + 5 * datasets.make_circles(n_samples=100)[0]\n",
    "\n",
    "# plot the point cloud\n",
    "plot_point_cloud(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default arguments\n",
    "\n",
    "Using default arguments is possible and easy: unfortunately it may take some time as you will not unlock the parallised computations...\n",
    "\n",
    "### A word on persistence diagrams\n",
    "One of the most effective way of plotting the persistent topological features is to plot them in the plane $(b, d)$ whose axes are the birth and death filtration values, i.e. the values where the topological feature is created (e.g. the circle is formed) and when the feature is destroyed (e.g. a circle is filled up). Hence, the more the points are far from the diagonal $b = d$, the more a topological feature is *persistent*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the persistence diagram\n",
    "dgm = ripser_parallel(data)\n",
    "\n",
    "# convert to gtda format\n",
    "dgm_gtda = _postprocess_diagrams([dgm[\"dgms\"]], \"ripser\", (0, 1), np.inf, True)[0]\n",
    "\n",
    "# plot the persistence diagram\n",
    "plot_diagram(dgm_gtda, homology_dimensions=(0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing the basis field\n",
    "\n",
    "It is possible to change the basis field of the homology group (actually, a vector space in this case!), to any finite filed in (prime) characteristic.\n",
    "\n",
    "The default is $\\mathbb F_2$, but it can be generalised to any $\\mathbb F_p$, $p$ prime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the persistence diagram\n",
    "dgm = ripser_parallel(data, coeff=7)\n",
    "\n",
    "# convert to gtda format\n",
    "dgm_gtda = _postprocess_diagrams([dgm[\"dgms\"]], \"ripser\", (0, 1), np.inf, True)[0]\n",
    "\n",
    "# plot\n",
    "plot_diagram(dgm_gtda, homology_dimensions=(0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Higher homology groups\n",
    "We can compute any order of homology, $H_0$,$H_1$,$H_2$,â€¦\n",
    "\n",
    "By default, we only compute $H_0$ and $H_1$. \n",
    "\n",
    "You can specify a larger group by setting the argument `maxdim=p`. It practice, anything above $H_1$ will benefit more substantially form parallelisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the persistence diagram\n",
    "dgm = ripser_parallel(data, maxdim=2)\n",
    "\n",
    "# comnvert to gtda format\n",
    "dgm_gtda = _postprocess_diagrams([dgm[\"dgms\"]], \"ripser\", (0, 1, 2), np.inf, True)[0]\n",
    "\n",
    "# plot\n",
    "plot_diagram(dgm_gtda, homology_dimensions=(0, 1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify a maximum radius\n",
    "\n",
    "We can decide what is the maximum size of the bubbles and stop the computations there. With less simplices to compute, the computations will be faster if you specify such thresholds. In order to do so, please add the argument `thresh=2.5`.\n",
    "\n",
    "#### Warning\n",
    "Reducing the threshold implies that topological features that only appear at a large radius (a.k.a. filtration value) may not be present at all in your persistence diagram or that some features may not die (as in the example below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the persistence diagram\n",
    "dgm = ripser_parallel(data, thresh=2.5)\n",
    "\n",
    "# convert to gtda format\n",
    "dgm_gtda = _postprocess_diagrams([dgm[\"dgms\"]], \"ripser\", (0, 1), np.inf, True)[0]\n",
    "\n",
    "# plot\n",
    "plot_diagram(dgm_gtda, homology_dimensions=(0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edge Collapser integration\n",
    "\n",
    "By setting the optional parameter `collapse_edges` to `True`, the [Edge Collapse](https://hal.inria.fr/hal-02873740/document) algorithm is used before performing any matrix reduction. This algorithm flags some of the edges as *dominated* and removes them completely from the filtration. This can lead to a greatly sparsified filtration and therefore to immense speed-ups especially when high homology dimensions are required.\n",
    "\n",
    "**Persistent barcodes computed with or without edge collapses are exactly the same**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the persistence diagram\n",
    "dgm = ripser_parallel(data, collapse_edges=True)\n",
    "\n",
    "# convert to gtda format\n",
    "dgm_gtda = _postprocess_diagrams([dgm[\"dgms\"]], \"ripser\", (0, 1), np.inf, True)[0]\n",
    "\n",
    "# plot\n",
    "plot_diagram(dgm_gtda, homology_dimensions=(0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve flag persistence generators\n",
    "\n",
    "You can retrieve the vertices and edges (pairs of vertex indices) responsible for the creation/destruction of persistent topological features by passing `return_generators=True`. A new entry is added to the dictionary output by `ripser_parallel`, with key `\"gens\"` and corresponding value a tuple of length 4 organized schematically as follows:\n",
    "\n",
    "  0. vertices creating and edges destroying *finite* $0$-dimensional features;\n",
    "  1. edges creating and destroying *finite* $d$-dimensional features, $d \\geq 1$;\n",
    "  2. vertices creating *infinite* $0$-dimensional features;\n",
    "  3. edges creating *infinite* $d$-dimensional features, $d \\geq 1$.\n",
    "\n",
    "In the case of entries 1 and 3 (higher dimensions), that information is organized by homology dimension. So, for example, calling `gens` this tuple (value in the dictionary):\n",
    "\n",
    "  - `gens[1]` and `gens[3]` are lists containing `maxdim` 2D integer `numpy` arrays, while `gens[0]` and `gens[2]` are `numpy` arrays;\n",
    "  - the edges creating and destroying finite features in dimension 1 are stored in `gens_finite_1 = gens[1][0]`;\n",
    "  - `gens_finite_1` is a 2D integer `numpy` array with as many rows as there are finite features in dimension 1;\n",
    "  - The `i`th finite feature in the 1-dimensional barcode is created by edge `gens_finite_1[i, :2]` and destroyed by edge `gens_finite_1[i, 2:]`.\n",
    "\n",
    "This way of presenting persistence birth and death vertices/edges agrees with other persistent homology packages and in particular with [GUDHI](http://gudhi.gforge.inria.fr/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the persistence information\n",
    "persistence_info = ripser_parallel(data, return_generators=True)\n",
    "gens = persistence_info['gens']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us visualize the 1-dimensional generators for our point cloud, labelling them by the positional index of the corresponding feature in the persistence diagram and using blue for creation and red for destruction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the point cloud\n",
    "fig = plot_point_cloud(data)\n",
    "\n",
    "# In blue are the edges that create a finite persistent topological features in dimension 1.\n",
    "# In red are the edges that destroy a finite persistent topological feature in dimension 1.\n",
    "for i, edges in enumerate(gens[1][0]):\n",
    "    birth_edge = edges[0:2]\n",
    "    death_edge = edges[2:4]\n",
    "    x0_create, y0_create = data[birth_edge[0]]\n",
    "    x1_create, y1_create = data[birth_edge[1]]\n",
    "    x0_destroy, y0_destroy = data[death_edge[0]]\n",
    "    x1_destroy, y1_destroy  = data[death_edge[1]]  \n",
    "\n",
    "    fig.add_shape(type='line',\n",
    "                  x0=x0_create,\n",
    "                  y0=y0_create,\n",
    "                  x1=x1_create,\n",
    "                  y1=y1_create,\n",
    "                  line=dict(color='Blue'))\n",
    "    fig.add_shape(type='line',\n",
    "                  x0=x0_destroy,\n",
    "                  y0=y0_destroy,\n",
    "                  x1=x1_destroy,\n",
    "                  y1=y1_destroy,\n",
    "                  line=dict(color='Red'))\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=[0.5 * (x0_create + x1_create) + 0.2, 0.5 * (x0_destroy + x1_destroy) + 0.2],\n",
    "                   y=[0.5 * (y0_create + y1_create), 0.5 * (y0_destroy + y1_destroy)],\n",
    "                   text=[str(i), str(i)],\n",
    "                   mode=\"text\")\n",
    "    )\n",
    "\n",
    "fig.update_layout(showlegend=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unleash multiple threads\n",
    "\n",
    "By changing the parameter `n_threads=N`, with `N >= -1`, you can parallelise the computation of the matrix reduction. This parallelisation is different from the `n_jobs` one that you can use on [giotto-tda](https://giotto-ai.github.io/gtda-docs/0.4.0/modules/generated/homology/gtda.homology.VietorisRipsPersistence.html#gtda.homology.VietorisRipsPersistence): the latter parallelises over multiple point clouds, whereas the former better distributes the computations for a single point cloud. With powerful enough machines, you can, of course, exploit both of the parallelisations!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"images/multithread.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the persistence diagram\n",
    "dgm = ripser_parallel(data, n_threads=8, maxdim=5)\n",
    "\n",
    "# convert to gtda format\n",
    "dgm_gtda = _postprocess_diagrams([dgm[\"dgms\"]], \"ripser\", (0, 1, 2, 3, 4, 5), np.inf, True)[0]\n",
    "\n",
    "# plot\n",
    "plot_diagram(dgm_gtda, homology_dimensions=(0, 1, 2, 3, 4, 5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
